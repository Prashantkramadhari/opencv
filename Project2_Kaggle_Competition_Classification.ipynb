{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n",
    "\n",
    "#### Maximum Points: 100\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hdd/tools/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/media/hdd/tools/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/media/hdd/tools/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/media/hdd/tools/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/media/hdd/tools/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/media/hdd/tools/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torchvision.transforms.functional as TF\n",
    "import glob\n",
    "from PIL import Image\n",
    "from sklearn.utils import class_weight\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from onecyclelr import OneCycleLR\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.utils.tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "df['class']=df['class'].astype('category')\n",
    "d = dict(enumerate(df['class'].cat.categories))\n",
    "df['class'] = df['class'].cat.codes\n",
    "\n",
    "\n",
    "train_df,val_df= train_test_split(df, test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3cd1ffa240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['class'].hist(bins=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3ccff7b898>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAV4klEQVR4nO3dbWxT593H8V9sUwoNMU4ckiUL2lKCVjQKQjDSdFEYeAiVDnFHVVQQQ60qsjRsKIm2FnUSrcSmecvcZK0SMU3dA/QNedGk625pSCZtkMgk0mSojLRdoTAVkWESm6fyUJyc+0VV7wbCnJxj4+Tq9/Om8bHPOf//OcmP08uXj7Msy7IEADCKK9MFAABSj3AHAAMR7gBgIMIdAAxEuAOAgQh3ADCQJ9MFfOHs2bO21/X7/RoeHk5hNZlhSh8SvUxFpvQh0csXioqK7vocV+4AYCDCHQAMlHRYpr29XQMDA/J6vQqFQpKklpaWxDDK1atXNXv2bDU3NysSiaixsTHxvwplZWWqra1NY/kAgPEkDfdVq1Zp3bp1amtrSyxrbGxM/Lx3717Nnj078biwsFDNzc0pLhMAMBlJh2UWLVqk7OzscZ+zLEt/+9vf9Oijj6a8MACAfY5my7z//vvyer36yle+klgWiUT03HPPadasWXryySf10EMPjbtuOBxWOByWJAWDQfn9ftt1eDweR+tPFab0IdHLVGRKHxK9TGi7TlY+fPjwLVftPp9P7e3tmjNnjj7++GM1NzcrFArdMmzzhUAgoEAgkHjsZFqTKdOiTOlDopepyJQ+JHr5QlqmQo6OjurIkSOqqKhILJsxY4bmzJkjSSotLVVBQYGGhobs7gIAYJPtcD927JiKioqUl5eXWHbp0iWNjY1Jks6dO6ehoSEVFBQ4rxIAMClJh2VaW1s1ODioy5cvq66uTjU1NVq9evUdQzKSNDg4qI6ODrndbrlcLm3btu2ub8ZOF6PbNqRt2+7f/Tlt2wbw5ZY03BsaGsZdvn379juWlZeXq7y83HlVAABH+IQqABhoytw4DEBmpXMIUmIY8l7jyh0ADES4A4CBCHcAMBDhDgAGItwBwECEOwAYiHAHAAMR7gBgIMIdAAxEuAOAgQh3ADAQ4Q4ABiLcAcBAhDsAGIhwBwADEe4AYCDCHQAMRLgDgIEIdwAwUNLvUG1vb9fAwIC8Xq9CoZAkqaOjQwcPHlROTo4kadOmTVq2bJkkqbOzU93d3XK5XHr66ae1dOnSNJYPABhP0nBftWqV1q1bp7a2tluWr1+/Xhs23PqFumfOnFFvb69efvllxWIx7d69W7/5zW/kcvE/CABwLyVN3UWLFik7O3tCG+vr61NFRYVmzJihefPmqbCwUCdOnHBcJABgcpJeud/NgQMHdOjQIZWWlmrr1q3Kzs5WNBpVWVlZ4jW5ubmKRqPjrh8OhxUOhyVJwWBQfr/fbinyeDyO1v9vzqVlq5+7veZ09nGv0cvUk6yPdP6uS3f+vjthyjmR0teLrXBfu3atnnjiCUnS/v37tXfvXtXX18uyrAlvIxAIKBAIJB4PDw/bKUXS5780TtbPlNtrnq59jIdepp5M95HKfWe6l1Ry0ktRUdFdn7M1GD537ly5XC65XC6tWbNGJ0+elCTl5eVpZGQk8bpoNKrc3Fw7uwAAOGAr3GOxWOLnI0eOqKSkRJK0fPly9fb26ubNm4pEIhoaGtKCBQtSUykAYMKSDsu0trZqcHBQly9fVl1dnWpqanT8+HGdPn1aWVlZys/PV21trSSppKREjzzyiJqamuRyufTMM88wUwYAMiBpuDc0NNyxbPXq1Xd9fXV1taqrq51VBQBwhMtqADAQ4Q4ABiLcAcBAhDsAGIhwBwADEe4AYCDCHQAMRLgDgIEIdwAwEOEOAAYi3AHAQIQ7ABiIcAcAAxHuAGAgwh0ADES4A4CBbH1B9lRz7n8qMl0CAEwpXLkDgIEIdwAwEOEOAAYi3AHAQEnfUG1vb9fAwIC8Xq9CoZAkad++ferv75fH41FBQYHq6+v1wAMPKBKJqLGxUUVFRZKksrIy1dbWprcDAMAdkob7qlWrtG7dOrW1tSWWPfzww9q8ebPcbrdef/11dXZ2asuWLZKkwsJCNTc3p69ifCmMbtuQtm27f/fntG0bmCqSDsssWrRI2dnZtyxbsmSJ3G63JGnhwoWKRqPpqQ4AYIvjee7d3d2qqPjPPPNIJKLnnntOs2bN0pNPPqmHHnpo3PXC4bDC4bAkKRgMyu/3267hnO01M+v2nj0ej6PjMJU47SWd53SydZlyXpL1ke6/o1QeQ1POiZS+XhyF+xtvvCG3263KykpJks/nU3t7u+bMmaOPP/5Yzc3NCoVCmj179h3rBgIBBQKBxOPh4WEnpUxLt/fs9/uNOQ5TuZfJ1jWVe5mMTPeRyn1nupdUctLLF+9vjsf2bJl33nlH/f392rFjh7KysiRJM2bM0Jw5cyRJpaWlKigo0NDQkN1dAABsshXuR48e1Ztvvqnnn39eM2fOTCy/dOmSxsbGJEnnzp3T0NCQCgoKUlMpAGDCkg7LtLa2anBwUJcvX1ZdXZ1qamrU2dmpeDyu3bt3S/rPlMfBwUF1dHTI7XbL5XJp27Ztd7wZCwBIv6Th3tDQcMey1atXj/va8vJylZeXO68KAOAIn1AFAAMR7gBgICPu5w4A6ZLOT0tLkjp707JZrtwBwECEOwAYiHAHAAMR7gBgIMIdAAxEuAOAgQh3ADAQ4Q4ABiLcAcBAhDsAGIhwBwADEe4AYCDCHQAMRLgDgIG45W8G3X4r0XMp3r77d39O8RYBTBdcuQOAgQh3ADAQ4Q4ABko65t7e3q6BgQF5vV6FQiFJ0pUrV9TS0qLz588rPz9fjY2Nys7OliR1dnaqu7tbLpdLTz/9tJYuXZreDgAAd0h65b5q1Sq98MILtyzr6urS4sWL9corr2jx4sXq6uqSJJ05c0a9vb16+eWX9dOf/lSvvfaaxsbG0lM5AOCukob7okWLElflX+jr61NVVZUkqaqqSn19fYnlFRUVmjFjhubNm6fCwkKdOHEiDWUDAP4bW1MhL168KJ/PJ0ny+Xy6dOmSJCkajaqsrCzxutzcXEWj0XG3EQ6HFQ6HJUnBYFB+v99OKZJSP4XQFE6OqVMej2fKntPJ1uW0l6kiWR/p/jtK5TG8l+ck3cclXb2kdJ67ZVkTfm0gEFAgEEg8Hh4eTmUpUGaPqd/vn7LndLJ1TeVeJiPTfaRy35nuJZXi8bjtXoqKiu76nK3ZMl6vV7FYTJIUi8WUk5MjScrLy9PIyEjiddFoVLm5uXZ2AQBwwFa4L1++XD09PZKknp4erVixIrG8t7dXN2/eVCQS0dDQkBYsWJC6agEAE5J0WKa1tVWDg4O6fPmy6urqVFNTo40bN6qlpUXd3d3y+/1qamqSJJWUlOiRRx5RU1OTXC6XnnnmGblcTKUHgHstabg3NDSMu3zXrl3jLq+urlZ1dbWzqpASt9+7JpW4bw0wtXFZDQAGItwBwEDc8hdIoXQOhUkMh2HiCHd86Uw2gPmQHKYjhmUAwECEOwAYiHAHAAMR7gBgIMIdAAxEuAOAgQh3ADAQ4Q4ABiLcAcBAhDsAGIhwBwADEe4AYCDCHQAMRLgDgIEIdwAwEOEOAAYi3AHAQLa/iens2bNqaWlJPI5EIqqpqdGnn36qgwcPKicnR5K0adMmLVu2zHmlAIAJsx3uRUVFam5uliSNjY3pBz/4gb71rW/p7bff1vr167VhQ3q/SxIAcHcpGZY5duyYCgsLlZ+fn4rNAQAcSskXZB8+fFiPPvpo4vGBAwd06NAhlZaWauvWrcrOzk7FbgAAE+Q43OPxuPr7+7V582ZJ0tq1a/XEE09Ikvbv36+9e/eqvr7+jvXC4bDC4bAkKRgMyu/3266Bb6e/95KdL4/HwzlNAyfHNNk5Sfcxd1L77Zz+fk1Guo9LunpxHO5///vf9fWvf11z586VpMR/JWnNmjX65S9/Oe56gUBAgUAg8Xh4eNhpKbiHkp0vv9/POU0DJ8c00+cklfvOdC+pFI/HbfdSVFR01+ccj7nfPiQTi8USPx85ckQlJSVOdwEAmCRHV+43btzQe++9p9ra2sSy119/XadPn1ZWVpby8/NveQ4AcG84CveZM2fq97///S3LfvSjHzkqCADgHJ9QBQADEe4AYCDCHQAMRLgDgIEIdwAwUEpuPwAAmTS6jRsV3o4rdwAwEOEOAAYi3AHAQIQ7ABiIcAcAAxHuAGAgwh0ADMQ8dwD3RCrnovNNXclx5Q4ABiLcAcBAhDsAGIhwBwADEe4AYCDCHQAMRLgDgIEczXPfvn277r//frlcLrndbgWDQV25ckUtLS06f/688vPz1djYqOzs7FTVCwCYAMcfYnrxxReVk5OTeNzV1aXFixdr48aN6urqUldXl7Zs2eJ0NwCASUj5sExfX5+qqqokSVVVVerr60v1LgAASTi+cv/5z38uSfrud7+rQCCgixcvyufzSZJ8Pp8uXbrkdBcAgElyFO67d+9Wbm6uLl68qJ/97GcqKiqa8LrhcFjhcFiSFAwG5ff7bdfBfSbuvWTny+PxcE7TwMkxTXZOOOaZ4fRv5a7bdbJybm6uJMnr9WrFihU6ceKEvF6vYrGYfD6fYrHYLePx/18gEFAgEEg8Hh4edlIK7rFk58vv93NO08DJMeWcTE3xeNz2eflvF9S2x9yvX7+ua9euJX5+7733NH/+fC1fvlw9PT2SpJ6eHq1YscLuLgAANtm+cr948aJ+/etfS5JGR0f17W9/W0uXLtWDDz6olpYWdXd3y+/3q6mpKWXFAgAmxna4FxQUqLm5+Y7lc+bM0a5duxwVBQBwhk+oAoCBCHcAMBDhDgAG4jtUgWnEyfeQMo/9y4UrdwAwEOEOAAYi3AHAQIQ7ABiIcAcAAxHuAGAgwh0ADES4A4CBCHcAMBDhDgAGItwBwECEOwAYiHAHAANxV0jYkuzuhNyBEMgsrtwBwECEOwAYiHAHAAMR7gBgINtvqA4PD6utrU0XLlxQVlaWAoGAHnvsMXV0dOjgwYPKycmRJG3atEnLli1LWcEAgORsh7vb7db3v/99lZaW6tq1a9q5c6cefvhhSdL69eu1YYP973oEADhjO9x9Pp98Pp8kadasWSouLlY0Gk1ZYQAA+1Iyzz0SiejUqVNasGCBPvjgAx04cECHDh1SaWmptm7dquzs7DvWCYfDCofDkqRgMCi/3297/8ypBjBdeTweR/l3N1mWZVlONnD9+nW9+OKLqq6u1sqVK3XhwoXEePv+/fsVi8VUX1+fdDtnz561XUOyD9QAwFRV0Nmr4eFhW+sWFRXd9TlHs2Xi8bhCoZAqKyu1cuVKSdLcuXPlcrnkcrm0Zs0anTx50skuAAA22A53y7K0Z88eFRcX6/HHH08sj8ViiZ+PHDmikpISZxUCACbN9pj7hx9+qEOHDmn+/Pn6yU9+IunzaY+HDx/W6dOnlZWVpfz8fNXW1qasWADAxNgO92984xvq6Oi4Yzlz2gEg8/iEKgAYiHAHAAMR7gBgIMIdAAxEuAOAgQh3ADAQ4Q4ABiLcAcBAhDsAGIhwBwADEe4AYCDCHQAMRLgDgIEIdwAwEOEOAAYi3AHAQIQ7ABiIcAcAAxHuAGAgwh0ADES4A4CBPOna8NGjR/WHP/xBY2NjWrNmjTZu3JiuXQEAbpOWK/exsTG99tpreuGFF9TS0qLDhw/rzJkz6dgVAGAcaQn3EydOqLCwUAUFBfJ4PKqoqFBfX186dgUAGEdahmWi0ajy8vISj/Py8vTRRx/d8ppwOKxwOCxJCgaDKioqsr/D/33X/roAkGGO8u8u0nLlblnWHcuysrJueRwIBBQMBhUMBh3vb+fOnY63MRWY0odEL1ORKX1I9DIRaQn3vLw8jYyMJB6PjIzI5/OlY1cAgHGkJdwffPBBDQ0NKRKJKB6Pq7e3V8uXL0/HrgAA43C/9NJLL6V6oy6XS4WFhXr11Vf117/+VZWVlSovL0/1bm5RWlqa1u3fK6b0IdHLVGRKHxK9JJNljTdADgCY1viEKgAYiHAHAAOl7fYD94IptzgYHh5WW1ubLly4oKysLAUCAT322GOZLsu2sbEx7dy5U7m5udN6ytqnn36qPXv26JNPPlFWVpaeffZZLVy4MNNl2fKXv/xF3d3dysrKUklJierr63XfffdluqwJaW9v18DAgLxer0KhkCTpypUramlp0fnz55Wfn6/GxkZlZ2dnuNLkxutl37596u/vl8fjUUFBgerr6/XAAw8435k1TY2Ojlo//OEPrX//+9/WzZs3rR//+MfWJ598kumybIlGo9bJkycty7Ksq1evWjt27Ji2vViWZb311ltWa2ur9Ytf/CLTpTjy6quvWuFw2LIsy7p586Z15cqVDFdkz8jIiFVfX2/duHHDsizLCoVC1ttvv53Zoibh+PHj1smTJ62mpqbEsn379lmdnZ2WZVlWZ2entW/fvkyVNynj9XL06FErHo9blvV5X6nqZdoOy5h0iwOfz5d4t3zWrFkqLi5WNBrNcFX2jIyMaGBgQGvWrMl0KY5cvXpV77//vlavXi1J8ng8qbmaypCxsTF99tlnGh0d1WeffTatPneyaNGiO67K+/r6VFVVJUmqqqqaNn/74/WyZMkSud1uSdLChQtT9rc/bYdlJnKLg+koEono1KlTWrBgQaZLseWPf/yjtmzZomvXrmW6FEcikYhycnLU3t6uf/3rXyotLdVTTz2l+++/P9OlTVpubq6+973v6dlnn9V9992nJUuWaMmSJZkuy5GLFy8m/oHy+Xy6dOlShitKje7ublVUVKRkW9P2yt2awC0Oppvr168rFArpqaee0uzZszNdzqT19/fL6/UaMf94dHRUp06d0tq1a/WrX/1KM2fOVFdXV6bLsuXKlSvq6+tTW1ubfvvb3+r69es6dOhQpsvCbd544w253W5VVlamZHvTNtxNu8VBPB5XKBRSZWWlVq5cmelybPnwww/17rvvavv27WptbdU//vEPvfLKK5kuy5a8vDzl5eWprKxMklReXq5Tp05luCp7jh07pnnz5iknJ0cej0crV67UP//5z0yX5YjX61UsFpMkxWIx5eTkZLgiZ9555x319/drx44dKbtInbbhbtItDizL0p49e1RcXKzHH3880+XYtnnzZu3Zs0dtbW1qaGjQN7/5Te3YsSPTZdkyd+5c5eXl6ezZs5I+D8ivfvWrGa7KHr/fr48++kg3btyQZVk6duyYiouLM12WI8uXL1dPT48kqaenRytWrMhwRfYdPXpUb775pp5//nnNnDkzZdud1p9QHRgY0J/+9CeNjY3pO9/5jqqrqzNdki0ffPCBdu3apfnz5yf+1d60aZOWLVuW4crsO378uN56661pPRXy9OnT2rNnj+LxuObNm6f6+vppMd1uPB0dHert7ZXb7dbXvvY11dXVacaMGZkua0JaW1s1ODioy5cvy+v1qqamRitWrFBLS4uGh4fl9/vV1NQ0Lc7NeL10dnYqHo8n6i8rK1Ntba3jfU3rcAcAjG/aDssAAO6OcAcAAxHuAGAgwh0ADES4A4CBCHcAMBDhDgAG+j90G4rXHGJadQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_df['class'].hist(bins=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KenyafoodDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df,root_image,transform,test=False):\n",
    "        self.root_image = root_image\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.test = test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.root_image + str(self.df.iloc[idx, 0]) + '.jpg'\n",
    "        image= Image.open(img_path)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image)\n",
    "            \n",
    "        if self.test:\n",
    "            sample = img\n",
    "            return sample\n",
    "        else:\n",
    "            label = self.df.iloc[idx, 1]\n",
    "            label_ten = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "            sample = img,label_ten\n",
    "            return sample\n",
    "        \n",
    "    def __id__(self,idx):\n",
    "        return self.df.iloc[idx, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.485, 0.456, 0.406] \n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "train_tranform = transforms.Compose([\n",
    "        transforms.Resize(300),\n",
    "        transforms.CenterCrop(300),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=(-90, 90)),\n",
    "        transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomAffine(30, translate=None, scale=None, shear=None, resample=False, fillcolor=0),\n",
    "        transforms.ToTensor(),        \n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "val_tranform = transforms.Compose([\n",
    "        transforms.Resize(300),\n",
    "        transforms.CenterCrop(300),\n",
    "        transforms.ToTensor(),        \n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "test_tranform = transforms.Compose([\n",
    "        transforms.Resize(300),\n",
    "        transforms.CenterCrop(300),\n",
    "        transforms.ToTensor(),        \n",
    "        transforms.Normalize(mean, std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=KenyafoodDataset(train_df,'./images/images/',train_tranform)\n",
    "val_dataset=KenyafoodDataset(val_df,'./images/images/',val_tranform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pic=np.transpose(img,(1,2,0))\n",
    "#plt.imshow(pic)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, num_workers=4, data_augmentation=False):\n",
    "           \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=0,\n",
    "                                         shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=0,\n",
    "                                         shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 21  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 10 \n",
    "    epochs_count: int = 50\n",
    "    init_learning_rate: float = 0.002  # initial learning rate for lr scheduler\n",
    "    decay_rate: float = 0.1\n",
    "    log_interval: int = 500  \n",
    "    test_interval: int = 1  \n",
    "    data_root: str = \"./temp\" \n",
    "    num_workers: int = 2  \n",
    "    device: str = 'cuda'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int,tb_writer: SummaryWriter\n",
    ") -> None:\n",
    "    \n",
    "    # change model in training mood\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (its is medatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gardients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "        \n",
    "        if batch_idx % train_config.log_interval == 0 and batch_idx > 0:\n",
    "\n",
    "            total_batch = epoch_idx * len(train_loader.dataset)/train_config.batch_size + batch_idx\n",
    "            tb_writer.add_scalar('Loss/train-batch', loss.item(), total_batch)\n",
    "            tb_writer.add_scalar('Accuracy/train-batch', acc, total_batch)\n",
    "            \n",
    "            \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    print('Epoch: {} \\nTrain Loss: {:.6f} Acc: {:.4f}'.format(epoch_idx, epoch_loss, epoch_acc))\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    # \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_corect_predictions = 0\n",
    "    for data, target in test_loader:\n",
    "        indx_target = target.clone()\n",
    "        data = data.to(train_config.device)\n",
    "        \n",
    "        target = target.to(train_config.device)\n",
    "        \n",
    "        output = model(data)\n",
    "        # add loss for each mini batch\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1] \n",
    "        \n",
    "        # add correct prediction count\n",
    "        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "    # average over number of mini-batches\n",
    "    test_loss = test_loss / len(test_loader)  \n",
    "    \n",
    "    # average over number of dataset\n",
    "    accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n",
    "    \n",
    "    print(\n",
    "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, count_corect_predictions, len(test_loader.dataset), accuracy\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return test_loss, accuracy/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, device, model_dir='models', model_file_name='kenya_food_classifier_101.pt'):\n",
    "    \n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # make sure you transfer the model to cpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict \n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, optimizer, tb_writer, scheduler, system_configuration=SystemConfiguration(), \n",
    "         training_configuration=TrainingConfiguration(), data_augmentation=True):\n",
    "    \n",
    "    # system configuration\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    # batch size\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    # num_workers\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    # epochs\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    # if GPU is available use training config, \n",
    "    # else lowers batch_size, num_workers and epochs count\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        batch_size_to_set = 16\n",
    "        num_workers_to_set = 4\n",
    "\n",
    "    # data loader\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=batch_size_to_set,\n",
    "        num_workers=num_workers_to_set,\n",
    "        data_augmentation=data_augmentation\n",
    "    )\n",
    "    \n",
    "    # Update training configuration\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        batch_size=batch_size_to_set,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "        \n",
    "    # send model to device (GPU/CPU)\n",
    "    model.to(training_configuration.device)\n",
    "\n",
    "    best_loss = torch.tensor(np.inf)\n",
    "    \n",
    "    # epoch train/test loss\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    \n",
    "    # epch train/test accuracy\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    # trainig time measurement\n",
    "    t_begin = time.time()\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "             \n",
    "        # Train\n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch, tb_writer)\n",
    "        \n",
    "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
    "        \n",
    "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
    "        \n",
    "        # add scalar (loss/accuracy) to tensorboard\n",
    "        tb_writer.add_scalar('Loss/Train',train_loss, epoch)\n",
    "        tb_writer.add_scalar('Accuracy/Train', train_acc, epoch)\n",
    "\n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        \n",
    "        print(\n",
    "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
    "                elapsed_time, speed_epoch, speed_batch, eta\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # add time metadata to tensorboard\n",
    "        tb_writer.add_scalar('Time/elapsed_time', elapsed_time, epoch)\n",
    "        tb_writer.add_scalar('Time/speed_epoch', speed_epoch, epoch)\n",
    "        tb_writer.add_scalar('Time/speed_batch', speed_batch, epoch)\n",
    "        tb_writer.add_scalar('Time/eta', eta, epoch)\n",
    "\n",
    "        # Validate\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            \n",
    "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
    "        \n",
    "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
    "            \n",
    "            # add scalar (loss/accuracy) to tensorboard\n",
    "            tb_writer.add_scalar('Loss/Validation', current_loss, epoch)\n",
    "            tb_writer.add_scalar('Accuracy/Validation', current_accuracy, epoch)\n",
    "            \n",
    "            # add scalars (loss/accuracy) to tensorboard\n",
    "            tb_writer.add_scalars('Loss/train-val', {'train': train_loss, \n",
    "                                           'validation': current_loss}, epoch)\n",
    "            tb_writer.add_scalars('Accuracy/train-val', {'train': train_acc, \n",
    "                                               'validation': current_accuracy}, epoch)\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                print('Model Improved. Saving the Model...\\n')\n",
    "                save_model(model, device=training_configuration.device)\n",
    "                \n",
    "        # scheduler step/ update learning rate\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(current_loss)\n",
    "        \n",
    "                \n",
    "    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n",
    "    \n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_and_scheduler(model):\n",
    "    train_config = TrainingConfiguration()\n",
    "\n",
    "    init_learning_rate = train_config.init_learning_rate\n",
    "\n",
    "    # optimizer\n",
    "    #optimizer = optim.SGD( model.parameters(), lr = 1e-7, momentum = 0.9)\n",
    "    optimizer = optim.SGD( model.parameters(), lr = 0.001,momentum = 0.9)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam( model.parameters(), lr = train_config.init_learning_rate)\n",
    "    decay_rate = train_config.decay_rate\n",
    "    lmbda = lambda epoch: 1/(1 + decay_rate * epoch)\n",
    "    \"\"\"\n",
    "\n",
    "    # Scheduler\n",
    "    #scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lmbda)\n",
    "    #scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "    scheduler = CyclicLR(optimizer, base_lr=0.0002, max_lr=0.001,cycle_momentum = False)\n",
    "    #scheduler = CyclicLR(optimizer, base_lr=0.002, max_lr=0.01,cycle_momentum = False)\n",
    "\n",
    "    \n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_resnet(transfer_learning=False, num_class=13):\n",
    "    #resnet = models.resnext50_32x4d(pretrained=True)\n",
    "    resnet = models.resnet101(pretrained=True)\n",
    "\n",
    "    if transfer_learning:\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "    \"\"\"        \n",
    "    model = models.resnext50_32x4d(pretrained=True) \n",
    "    for param in model.parameters(): \n",
    "        param.requires_grad = False\n",
    "    for param in model.layer4: \n",
    "        param.requires_grad = True\n",
    "    \n",
    "    num_ftrs = model.fc.in_features   \n",
    "    model.fc = nn.Linear(num_ftrs, 13)\n",
    "    \"\"\" \n",
    "     \n",
    "    last_layer_in = resnet.fc.in_features\n",
    "     \n",
    "    resnet.fc = nn.Linear(last_layer_in, num_class)\n",
    "    \n",
    "    return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training starts here\n",
    "####*** FINE TUNING ***####\n",
    "\n",
    "model = pretrained_resnet(transfer_learning=False)\n",
    "# get optimizer and scheduler\n",
    "optimizer, scheduler = get_optimizer_and_scheduler(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from lr_finder import LRFinder\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                         batch_size=10,\n",
    "                                         num_workers=0,\n",
    "                                         shuffle=True)\n",
    "\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(train_loader, end_lr=100, num_iter=100)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n",
      "Train Loss: 2.044090 Acc: 0.3641\n",
      "Elapsed 514.70s, 514.70 s/epoch, 0.98 s/batch, ets 25220.41s\n",
      "\n",
      "Test set: Average loss: 1.4218, Accuracy: 787/1308 (60%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "Epoch: 1 \n",
      "Train Loss: 1.367670 Acc: 0.5787\n",
      "Elapsed 1110.98s, 555.49 s/epoch, 1.06 s/batch, ets 26663.43s\n",
      "\n",
      "Test set: Average loss: 1.0232, Accuracy: 900/1308 (69%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "Epoch: 2 \n",
      "Train Loss: 1.111784 Acc: 0.6463\n",
      "Elapsed 1697.23s, 565.74 s/epoch, 1.08 s/batch, ets 26589.89s\n",
      "\n",
      "Test set: Average loss: 0.9184, Accuracy: 914/1308 (70%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "Epoch: 3 \n",
      "Train Loss: 0.981339 Acc: 0.6819\n",
      "Elapsed 2287.86s, 571.96 s/epoch, 1.09 s/batch, ets 26310.37s\n",
      "\n",
      "Test set: Average loss: 0.8447, Accuracy: 952/1308 (73%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "Epoch: 4 \n",
      "Train Loss: 0.916964 Acc: 0.7060\n",
      "Elapsed 2881.36s, 576.27 s/epoch, 1.10 s/batch, ets 25932.28s\n",
      "\n",
      "Test set: Average loss: 0.7986, Accuracy: 981/1308 (75%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "Epoch: 5 \n",
      "Train Loss: 0.834751 Acc: 0.7319\n",
      "Elapsed 3478.57s, 579.76 s/epoch, 1.11 s/batch, ets 25509.55s\n",
      "\n",
      "Test set: Average loss: 0.7983, Accuracy: 979/1308 (75%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "Epoch: 6 \n",
      "Train Loss: 0.793920 Acc: 0.7450\n",
      "Elapsed 4072.97s, 581.85 s/epoch, 1.11 s/batch, ets 25019.65s\n",
      "\n",
      "Test set: Average loss: 0.7728, Accuracy: 997/1308 (76%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "Epoch: 7 \n",
      "Train Loss: 0.743360 Acc: 0.7582\n",
      "Elapsed 4661.42s, 582.68 s/epoch, 1.11 s/batch, ets 24472.45s\n",
      "\n",
      "Test set: Average loss: 0.7633, Accuracy: 987/1308 (75%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "Epoch: 8 \n",
      "Train Loss: 0.702372 Acc: 0.7718\n",
      "Elapsed 5247.94s, 583.10 s/epoch, 1.11 s/batch, ets 23907.26s\n",
      "\n",
      "Test set: Average loss: 0.7451, Accuracy: 998/1308 (76%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "Epoch: 9 \n",
      "Train Loss: 0.651864 Acc: 0.7836\n",
      "Elapsed 5841.96s, 584.20 s/epoch, 1.12 s/batch, ets 23367.83s\n",
      "\n",
      "Test set: Average loss: 0.7503, Accuracy: 998/1308 (76%)\n",
      "\n",
      "Epoch: 10 \n",
      "Train Loss: 0.601672 Acc: 0.8033\n",
      "Elapsed 6430.60s, 584.60 s/epoch, 1.12 s/batch, ets 22799.38s\n",
      "\n",
      "Test set: Average loss: 0.7241, Accuracy: 1011/1308 (77%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "Epoch: 11 \n",
      "Train Loss: 0.569552 Acc: 0.8156\n",
      "Elapsed 7032.82s, 586.07 s/epoch, 1.12 s/batch, ets 22270.59s\n",
      "\n",
      "Test set: Average loss: 0.7408, Accuracy: 995/1308 (76%)\n",
      "\n",
      "Epoch: 12 \n",
      "Train Loss: 0.540612 Acc: 0.8200\n",
      "Elapsed 7627.49s, 586.73 s/epoch, 1.12 s/batch, ets 21709.02s\n",
      "\n",
      "Test set: Average loss: 0.6843, Accuracy: 1027/1308 (79%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "Epoch: 13 \n",
      "Train Loss: 0.524449 Acc: 0.8273\n",
      "Elapsed 8227.76s, 587.70 s/epoch, 1.12 s/batch, ets 21157.11s\n",
      "\n",
      "Test set: Average loss: 0.7565, Accuracy: 1021/1308 (78%)\n",
      "\n",
      "Epoch: 14 \n",
      "Train Loss: 0.465855 Acc: 0.8488\n",
      "Elapsed 8827.35s, 588.49 s/epoch, 1.13 s/batch, ets 20597.16s\n",
      "\n",
      "Test set: Average loss: 0.7729, Accuracy: 1008/1308 (77%)\n",
      "\n",
      "Epoch: 15 \n",
      "Train Loss: 0.449911 Acc: 0.8512\n",
      "Elapsed 9419.55s, 588.72 s/epoch, 1.13 s/batch, ets 20016.53s\n",
      "\n",
      "Test set: Average loss: 0.7733, Accuracy: 1010/1308 (77%)\n",
      "\n",
      "Epoch: 16 \n",
      "Train Loss: 0.438303 Acc: 0.8550\n",
      "Elapsed 10004.98s, 588.53 s/epoch, 1.13 s/batch, ets 19421.42s\n",
      "\n",
      "Test set: Average loss: 0.7570, Accuracy: 1011/1308 (77%)\n",
      "\n",
      "Epoch: 17 \n",
      "Train Loss: 0.413523 Acc: 0.8656\n",
      "Elapsed 10579.85s, 587.77 s/epoch, 1.12 s/batch, ets 18808.63s\n",
      "\n",
      "Test set: Average loss: 0.7563, Accuracy: 1000/1308 (76%)\n",
      "\n",
      "Epoch: 18 \n",
      "Train Loss: 0.381281 Acc: 0.8793\n",
      "Elapsed 11145.59s, 586.61 s/epoch, 1.12 s/batch, ets 18184.91s\n",
      "\n",
      "Test set: Average loss: 0.8252, Accuracy: 992/1308 (76%)\n",
      "\n",
      "Epoch: 19 \n",
      "Train Loss: 0.346769 Acc: 0.8885\n",
      "Elapsed 11710.29s, 585.51 s/epoch, 1.12 s/batch, ets 17565.43s\n",
      "\n",
      "Test set: Average loss: 0.8115, Accuracy: 1003/1308 (77%)\n",
      "\n",
      "Epoch: 20 \n",
      "Train Loss: 0.323859 Acc: 0.8922\n",
      "Elapsed 12277.41s, 584.64 s/epoch, 1.12 s/batch, ets 16954.51s\n",
      "\n",
      "Test set: Average loss: 0.7765, Accuracy: 1005/1308 (77%)\n",
      "\n",
      "Epoch: 21 \n",
      "Train Loss: 0.301324 Acc: 0.9093\n",
      "Elapsed 12840.40s, 583.65 s/epoch, 1.12 s/batch, ets 16342.32s\n",
      "\n",
      "Test set: Average loss: 0.7896, Accuracy: 1011/1308 (77%)\n",
      "\n",
      "Epoch: 22 \n",
      "Train Loss: 0.292188 Acc: 0.9042\n",
      "Elapsed 13416.47s, 583.32 s/epoch, 1.12 s/batch, ets 15749.77s\n",
      "\n",
      "Test set: Average loss: 0.8519, Accuracy: 997/1308 (76%)\n",
      "\n",
      "Epoch: 23 \n",
      "Train Loss: 0.264872 Acc: 0.9180\n",
      "Elapsed 13986.25s, 582.76 s/epoch, 1.11 s/batch, ets 15151.77s\n",
      "\n",
      "Test set: Average loss: 0.8294, Accuracy: 1012/1308 (77%)\n",
      "\n",
      "Epoch: 24 \n",
      "Train Loss: 0.255388 Acc: 0.9198\n",
      "Elapsed 14549.74s, 581.99 s/epoch, 1.11 s/batch, ets 14549.74s\n",
      "\n",
      "Test set: Average loss: 0.8740, Accuracy: 989/1308 (76%)\n",
      "\n",
      "Epoch: 25 \n",
      "Train Loss: 0.249343 Acc: 0.9228\n",
      "Elapsed 15108.31s, 581.09 s/epoch, 1.11 s/batch, ets 13946.13s\n",
      "\n",
      "Test set: Average loss: 0.8914, Accuracy: 976/1308 (75%)\n",
      "\n",
      "Epoch: 26 \n",
      "Train Loss: 0.233529 Acc: 0.9264\n",
      "Elapsed 15676.24s, 580.60 s/epoch, 1.11 s/batch, ets 13353.83s\n",
      "\n",
      "Test set: Average loss: 0.8893, Accuracy: 988/1308 (76%)\n",
      "\n",
      "Epoch: 27 \n",
      "Train Loss: 0.230144 Acc: 0.9281\n",
      "Elapsed 16252.90s, 580.46 s/epoch, 1.11 s/batch, ets 12770.13s\n",
      "\n",
      "Test set: Average loss: 0.9344, Accuracy: 966/1308 (74%)\n",
      "\n",
      "Epoch: 28 \n",
      "Train Loss: 0.196233 Acc: 0.9407\n",
      "Elapsed 16831.78s, 580.41 s/epoch, 1.11 s/batch, ets 12188.53s\n",
      "\n",
      "Test set: Average loss: 0.8926, Accuracy: 973/1308 (74%)\n",
      "\n",
      "Epoch: 29 \n",
      "Train Loss: 0.197462 Acc: 0.9370\n",
      "Elapsed 17413.46s, 580.45 s/epoch, 1.11 s/batch, ets 11608.98s\n",
      "\n",
      "Test set: Average loss: 0.9209, Accuracy: 984/1308 (75%)\n",
      "\n",
      "Epoch: 30 \n",
      "Train Loss: 0.184407 Acc: 0.9384\n",
      "Elapsed 17994.78s, 580.48 s/epoch, 1.11 s/batch, ets 11029.06s\n",
      "\n",
      "Test set: Average loss: 0.9383, Accuracy: 977/1308 (75%)\n",
      "\n",
      "Epoch: 31 \n",
      "Train Loss: 0.165024 Acc: 0.9466\n",
      "Elapsed 18564.63s, 580.14 s/epoch, 1.11 s/batch, ets 10442.60s\n",
      "\n",
      "Test set: Average loss: 0.9450, Accuracy: 994/1308 (76%)\n",
      "\n",
      "Epoch: 32 \n",
      "Train Loss: 0.158111 Acc: 0.9541\n",
      "Elapsed 19139.39s, 579.98 s/epoch, 1.11 s/batch, ets 9859.68s\n",
      "\n",
      "Test set: Average loss: 1.0037, Accuracy: 973/1308 (74%)\n",
      "\n",
      "Epoch: 33 \n",
      "Train Loss: 0.153401 Acc: 0.9533\n",
      "Elapsed 19708.64s, 579.67 s/epoch, 1.11 s/batch, ets 9274.65s\n",
      "\n",
      "Test set: Average loss: 0.9878, Accuracy: 972/1308 (74%)\n",
      "\n",
      "Epoch: 34 \n",
      "Train Loss: 0.146665 Acc: 0.9564\n",
      "Elapsed 20282.64s, 579.50 s/epoch, 1.11 s/batch, ets 8692.56s\n",
      "\n",
      "Test set: Average loss: 0.9440, Accuracy: 1009/1308 (77%)\n",
      "\n",
      "Epoch: 35 \n",
      "Train Loss: 0.125887 Acc: 0.9630\n",
      "Elapsed 20851.74s, 579.22 s/epoch, 1.11 s/batch, ets 8109.01s\n",
      "\n",
      "Test set: Average loss: 0.9673, Accuracy: 1000/1308 (76%)\n",
      "\n",
      "Epoch: 36 \n",
      "Train Loss: 0.127381 Acc: 0.9618\n",
      "Elapsed 21450.67s, 579.75 s/epoch, 1.11 s/batch, ets 7536.72s\n",
      "\n",
      "Test set: Average loss: 0.9348, Accuracy: 989/1308 (76%)\n",
      "\n",
      "Epoch: 37 \n",
      "Train Loss: 0.109444 Acc: 0.9684\n",
      "Elapsed 22034.25s, 579.85 s/epoch, 1.11 s/batch, ets 6958.19s\n",
      "\n",
      "Test set: Average loss: 0.9681, Accuracy: 985/1308 (75%)\n",
      "\n",
      "Epoch: 38 \n",
      "Train Loss: 0.114603 Acc: 0.9688\n",
      "Elapsed 22626.94s, 580.18 s/epoch, 1.11 s/batch, ets 6381.96s\n",
      "\n",
      "Test set: Average loss: 0.9771, Accuracy: 994/1308 (76%)\n",
      "\n",
      "Epoch: 39 \n",
      "Train Loss: 0.113041 Acc: 0.9684\n",
      "Elapsed 23276.39s, 581.91 s/epoch, 1.11 s/batch, ets 5819.10s\n",
      "\n",
      "Test set: Average loss: 1.0415, Accuracy: 983/1308 (75%)\n",
      "\n",
      "Epoch: 40 \n",
      "Train Loss: 0.119281 Acc: 0.9640\n",
      "Elapsed 23861.49s, 581.99 s/epoch, 1.11 s/batch, ets 5237.89s\n",
      "\n",
      "Test set: Average loss: 1.0010, Accuracy: 986/1308 (75%)\n",
      "\n",
      "Epoch: 41 \n",
      "Train Loss: 0.103158 Acc: 0.9690\n",
      "Elapsed 24436.81s, 581.83 s/epoch, 1.11 s/batch, ets 4654.63s\n",
      "\n",
      "Test set: Average loss: 1.0115, Accuracy: 1003/1308 (77%)\n",
      "\n",
      "Epoch: 42 \n",
      "Train Loss: 0.098557 Acc: 0.9721\n",
      "Elapsed 25008.38s, 581.59 s/epoch, 1.11 s/batch, ets 4071.13s\n",
      "\n",
      "Test set: Average loss: 0.9898, Accuracy: 992/1308 (76%)\n",
      "\n",
      "Epoch: 43 \n",
      "Train Loss: 0.098439 Acc: 0.9697\n",
      "Elapsed 25579.51s, 581.35 s/epoch, 1.11 s/batch, ets 3488.12s\n",
      "\n",
      "Test set: Average loss: 0.9699, Accuracy: 1005/1308 (77%)\n",
      "\n",
      "Epoch: 44 \n",
      "Train Loss: 0.093978 Acc: 0.9729\n",
      "Elapsed 26154.09s, 581.20 s/epoch, 1.11 s/batch, ets 2906.01s\n",
      "\n",
      "Test set: Average loss: 0.9696, Accuracy: 997/1308 (76%)\n",
      "\n",
      "Epoch: 45 \n",
      "Train Loss: 0.084187 Acc: 0.9769\n",
      "Elapsed 26728.36s, 581.05 s/epoch, 1.11 s/batch, ets 2324.21s\n",
      "\n",
      "Test set: Average loss: 0.9960, Accuracy: 990/1308 (76%)\n",
      "\n",
      "Epoch: 46 \n",
      "Train Loss: 0.081834 Acc: 0.9782\n",
      "Elapsed 27307.12s, 581.00 s/epoch, 1.11 s/batch, ets 1743.01s\n",
      "\n",
      "Test set: Average loss: 1.0125, Accuracy: 1001/1308 (77%)\n",
      "\n",
      "Epoch: 47 \n",
      "Train Loss: 0.087442 Acc: 0.9751\n",
      "Elapsed 27879.12s, 580.82 s/epoch, 1.11 s/batch, ets 1161.63s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9885, Accuracy: 993/1308 (76%)\n",
      "\n",
      "Epoch: 48 \n",
      "Train Loss: 0.080470 Acc: 0.9766\n",
      "Elapsed 28452.27s, 580.66 s/epoch, 1.11 s/batch, ets 580.66s\n",
      "\n",
      "Test set: Average loss: 1.0210, Accuracy: 1009/1308 (77%)\n",
      "\n",
      "Epoch: 49 \n",
      "Train Loss: 0.074759 Acc: 0.9792\n",
      "Elapsed 29032.31s, 580.65 s/epoch, 1.11 s/batch, ets 0.00s\n",
      "\n",
      "Test set: Average loss: 0.9975, Accuracy: 1003/1308 (77%)\n",
      "\n",
      "Total time: 29106.55, Best Loss: 0.684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tensorboard summary writer\n",
    "fine_tuning_sw = SummaryWriter('KenyaFood-resNext50/fine_tuning')   \n",
    "model, train_loss, train_acc, val_loss, val_acc = main(model, \n",
    "                                                       optimizer,\n",
    "                                                       fine_tuning_sw,\n",
    "                                                       scheduler,\n",
    "                                                       data_augmentation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_dir='models', model_file_name='kenya_food_classifier_101.pt'):\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # loading the model and getting model parameters by using load_state_dict\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, device, batch_input):\n",
    "    \n",
    "    # send model to cpu/cuda according to your system configuration\n",
    "    model.to(device)\n",
    "    \n",
    "    # it is important to do model.eval() before prediction\n",
    "    model.eval()\n",
    "\n",
    "    data = batch_input.to(device)\n",
    "\n",
    "    output = model(data)\n",
    "\n",
    "    # Score to probability using softmax\n",
    "    prob = F.softmax(output, dim=1)\n",
    "\n",
    "    # get the max probability\n",
    "    pred_prob = prob.data.max(dim=1)[0]\n",
    "    \n",
    "    # get the index of the max probability\n",
    "    pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_prediction(model, dataset, mean, std):\n",
    "    batch_size = 8\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        num_workers = 8\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        num_workers = 2\n",
    "   \n",
    "    \n",
    "    data_len = len(dataset)  \n",
    "    print('data_len=', data_len)\n",
    "    interval = int(data_len/batch_size)\n",
    "    \n",
    "\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    predictions = np.array([], dtype = int)\n",
    "    probability = np.array([])\n",
    "\n",
    "    for j in range(0, data_len, batch_size):\n",
    "        if((data_len - j) < batch_size):\n",
    "            batch_size = (data_len - j)\n",
    "        for i in range(j, j+batch_size):\n",
    "            index = i\n",
    "            trans_input = dataset[index]\n",
    "            inputs.append(trans_input)\n",
    "\n",
    "        inputs = torch.stack(inputs)\n",
    "        cls, prob = prediction(model, device, batch_input=inputs)\n",
    "        predictions = np.append(predictions, cls)\t\n",
    "        probability = np.append(probability, prob)\n",
    "        inputs = []\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_len= 1638\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model)\n",
    "\n",
    "test_dataset=KenyafoodDataset(df_test,'./images/images/',test_tranform,test=True)\n",
    "predictions = get_test_prediction(model, test_dataset,  mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name=['bhaji','chapati','githeri','kachumbari','kukuchoma','mandazi','masalachips','matoke','mukimo','nyamachoma',\n",
    "            'pilau','sukumawiki','ugali']\n",
    "label_test = [class_name[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the submission to the csv file\n",
    "submit_data = {'id': [], 'class': [] }\n",
    "#data_root = '/kaggle/input/pytorch-opencv-course-classification'\n",
    "#train_dataset =  KenyanFood13Dataset(data_root, train=True, image_shape=256 )\n",
    "\n",
    "for i in range(0, predictions.size):\n",
    "    img_id = test_dataset.__id__(i)\n",
    "    submit_data['id'].append(img_id)\n",
    "    submit_data['class'].append(label_test[i])\n",
    "\n",
    "\n",
    "submit_file = pd.DataFrame(submit_data)\n",
    "submit_file.to_csv('models/submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard dev upload --logdir 'KenyaFood-resNext50/fine_tuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
